{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWVdcdH9Flks"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import os\n",
        "from random import randint, random\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "\n",
        "def generate(dir_name, num_imgs):\n",
        "    # `torchvision.datasets.ImageFolder` requires a subfolder\n",
        "    os.makedirs(f'./msds2/{dir_name}/0', exist_ok=True)\n",
        "\n",
        "    labels = np.empty((num_imgs, 4, 4, 6), dtype=np.int32)\n",
        "    for count in range(num_imgs):\n",
        "        item_angle = random() * 180\n",
        "\n",
        "        img = Image.new('RGB', (32, 32), (0, 0, 0))\n",
        "        for i in range(4):\n",
        "            for j in range(4):\n",
        "                item = Image.new('RGBA', (8, 8), (255, 255, 255, 0))\n",
        "                draw = ImageDraw.Draw(item)\n",
        "\n",
        "                now_color = (\n",
        "                    randint(0, 255),\n",
        "                    randint(0, 255),\n",
        "                    randint(0, 255),\n",
        "                    255,\n",
        "                )\n",
        "                draw.ellipse((1, 3, 7, 5), now_color)\n",
        "                now_angle = item_angle + random() * 45\n",
        "                item = item.rotate(now_angle,\n",
        "                                   resample=Image.Resampling.BICUBIC)\n",
        "\n",
        "                now_pos = (\n",
        "                    i * 8 + randint(-1, 1),\n",
        "                    j * 8 + randint(-1, 1),\n",
        "                )\n",
        "                img.paste(item, now_pos, mask=item)\n",
        "\n",
        "                label = now_pos + (now_angle, ) + now_color[:3]\n",
        "                labels[count, i, j, :] = label\n",
        "\n",
        "        img.save(f'./msds2/{dir_name}/0/{count:05d}.png', compress_level=1)\n",
        "\n",
        "    with h5py.File(f'./msds2/{dir_name}_labels.hdf5', 'w') as f:\n",
        "        f.create_dataset('labels',\n",
        "                         data=labels,\n",
        "                         compression='gzip',\n",
        "                         shuffle=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "    generate('train', 9 * 10**4)\n",
        "    generate('test', 10**4)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LX8e4wCGpkQ"
      },
      "outputs": [],
      "source": [
        "# msds1_dataset.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Optional, Callable\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "class MSDS2(Dataset):\n",
        "    \"\"\"\n",
        "    Minimal PyTorch-style wrapper around the dataset generated by your script.\n",
        "\n",
        "    • Each sample returns:\n",
        "        img   –   torch.Tensor   (C, H, W)   –   by default in [0,1]\n",
        "        label –   torch.Tensor   (4, 4, 6)   –   (x, y, angle, R, G, B)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str | Path = \"./msds1\",\n",
        "        split: str = \"train\",            # \"train\" | \"test\"\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "        preload_labels: bool = True,     # load the entire HDF5 once; fine for 90k × 96 ints ≈ 35 MB\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        split = split.lower()\n",
        "        if split not in {\"train\", \"test\"}:\n",
        "            raise ValueError(f\"split must be 'train' or 'test', got {split!r}\")\n",
        "\n",
        "        self.img_dir = Path(root) / split / \"0\"\n",
        "        self.img_paths = sorted(self.img_dir.glob(\"*.png\"))          # 00000.png, 00001.png, …\n",
        "        if not self.img_paths:\n",
        "            raise FileNotFoundError(f\"No images found in {self.img_dir}\")\n",
        "\n",
        "        # ------ labels ------------------------------------------------------\n",
        "        h5_path = Path(root) / f\"{split}_labels.hdf5\"\n",
        "        if not h5_path.exists():\n",
        "            raise FileNotFoundError(h5_path)\n",
        "\n",
        "        if preload_labels:\n",
        "            with h5py.File(h5_path, \"r\") as f:\n",
        "                self.labels = torch.from_numpy(f[\"labels\"][...])     # (N, 4, 4, 6)\n",
        "        else:\n",
        "            # keep only the path; open lazily in __getitem__\n",
        "            self.labels = None\n",
        "            self._h5_path = h5_path\n",
        "\n",
        "        # ------ optional transforms ----------------------------------------\n",
        "        from torchvision.transforms import ToTensor\n",
        "        self.transform = transform or ToTensor()\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    # --------------------------------------------------------------------- #\n",
        "    def _lazy_load_label(self, idx: int) -> torch.Tensor:\n",
        "        \"\"\"Open the HDF5 file every time (safer with num_workers>0).\"\"\"\n",
        "        with h5py.File(self._h5_path, \"r\") as f:\n",
        "            arr = f[\"labels\"][idx]                   # (4, 4, 6) ndarray\n",
        "        return torch.from_numpy(arr)\n",
        "\n",
        "    # --------------------------------------------------------------------- #\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # --- image ---------------------------------------------------------\n",
        "        img = Image.open(self.img_paths[idx]).convert(\"RGB\")         # (32×32)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)                                # torch.FloatTensor\n",
        "\n",
        "        # --- label ---------------------------------------------------------\n",
        "        if self.labels is not None:                                  # pre-loaded\n",
        "            target = self.labels[idx]\n",
        "        else:                                                        # lazy path\n",
        "            target = self._lazy_load_label(idx)\n",
        "\n",
        "        if self.target_transform:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qobOeeIVFUR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "\n",
        "# -- transforms --------------------------------------------------------------\n",
        "transforms = Compose([\n",
        "    ToTensor()                         # PIL → [0,1] tenso\n",
        "])\n",
        "\n",
        "# -- datasets & loaders ------------------------------------------------------\n",
        "train_ds = MSDS2(root=\"./msds2\", split=\"train\", transform=transforms)\n",
        "test_ds  = MSDS2(root=\"./msds2\", split=\"test\",  transform=transforms)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=12,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "# ---- quick sanity check ----------------------------------------------------\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)   # torch.Size([128, 3, 32, 32])\n",
        "print(labels.shape)   # torch.Size([128, 4, 4, 6])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hy16dq0AWwm9",
        "outputId": "9894bd5d-5b5f-472f-c46b-e21cc63d27dd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "def show_images(data_loader, num_images: int = 6, *, denorm=None):\n",
        "    \"\"\"\n",
        "    Visualise `num_images` images from the first batch in `data_loader`.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    data_loader : torch.utils.data.DataLoader\n",
        "        Your existing loader (train or val).\n",
        "    num_images  : int\n",
        "        How many images from the batch to plot (<= batch_size).\n",
        "    denorm : callable or None\n",
        "        Optionally reverse any normalisation applied in your transforms.\n",
        "        Example:\n",
        "            denorm = lambda x: x * 0.5 + 0.5        # if you used Normalize(mean=.5, std=.5)\n",
        "    \"\"\"\n",
        "    # Grab one batch; no need to exhaust the iterator\n",
        "    images, labels = next(iter(data_loader))       # labels ignored for plotting\n",
        "    images = images[:num_images].cpu()\n",
        "\n",
        "    if denorm is not None:\n",
        "        images = denorm(images)\n",
        "\n",
        "    # torchvision.utils.make_grid puts them into one canvas\n",
        "    grid = torchvision.utils.make_grid(\n",
        "        images, nrow=num_images, padding=2, normalize=False\n",
        "    )\n",
        "    grid = grid.permute(1, 2, 0).numpy()           # (C,H,W) → (H,W,C) for matplotlib\n",
        "\n",
        "    plt.figure(figsize=(2 * num_images, 2))\n",
        "    plt.imshow(grid)\n",
        "    plt.title(f\"MSDS2 Dataset Images\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "show_images(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "POjzGs5LYdan"
      },
      "outputs": [],
      "source": [
        "from torch.nn import init\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CelebA\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.distributions as D\n",
        "import os\n",
        "from torch.nn.utils.parametrizations import weight_norm\n",
        "from torch.profiler import profile, record_function, ProfilerActivity, schedule\n",
        "from contextlib import nullcontext # Used to conditionally disable the profiler\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from math import sqrt, log\n",
        "from typing import List, Tuple, Dict, Any, Optional, Union\n",
        "import time\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.set_float32_matmul_precision('high')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DfSsD_xZYiFC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()\n",
        "        self.alpha = nn.Parameter(torch.ones(num_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(self.alpha * x)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, nres = 4, widths = [48, 512, 512, 48], final_scale = True):\n",
        "        assert widths[0] == widths[-1]\n",
        "\n",
        "        super().__init__()\n",
        "        self.res_blocks = nn.ModuleList(\n",
        "            [self.build_res_block(widths) for _ in range(nres)])\n",
        "\n",
        "        if final_scale:\n",
        "            self.scale = nn.Parameter(torch.zeros(widths[-1]))\n",
        "        else:\n",
        "            self.scale = None\n",
        "\n",
        "    def build_linear(self, in_features, out_features):\n",
        "        linear = nn.Linear(in_features, out_features)\n",
        "        bound = sqrt(2.81 * 3 / in_features)\n",
        "        nn.init.uniform_(linear.weight, -bound, bound)\n",
        "        nn.init.zeros_(linear.bias)\n",
        "        linear = weight_norm(linear)\n",
        "        return linear\n",
        "\n",
        "    def build_res_block(self, widths):\n",
        "        layers = []\n",
        "        for i in range(len(widths) - 1):\n",
        "            layers.append(Swish(widths[i]))\n",
        "            layers.append(self.build_linear(widths[i], widths[i + 1]))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for res_block in self.res_blocks:\n",
        "            x = (x + res_block(x)) / sqrt(2)\n",
        "\n",
        "        if self.scale is not None:\n",
        "            x = x * self.scale\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResidualNetwork(ResNet):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shape = x.shape  # (B*num_RG_blocks, C, K, K)\n",
        "        x = x.view(shape[0], -1)  # (B*num_RG_blocks, C*K*K)\n",
        "        x = super().forward(x)\n",
        "        x = x.view(shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aJ1cv1hAYmJm"
      },
      "outputs": [],
      "source": [
        "def create_masks(kernel_size: int, num_channels:int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    '''\n",
        "    Create checkerboard masks for the RNVP block.\n",
        "    Args:\n",
        "        kernel_size: The size of the kernel\n",
        "        num_channels: The number of channels in the input\n",
        "    Returns:\n",
        "        mask: The mask for the networks\n",
        "        comask: The complementary mask such that mask + comask = 1\n",
        "    '''\n",
        "    checkerboard = torch.from_numpy(np.indices((kernel_size, kernel_size)).sum(axis=0) % 2).float()\n",
        "    mask = checkerboard.unsqueeze(0).repeat(num_channels, 1, 1)\n",
        "    comask = 1 - mask\n",
        "    return mask, comask\n",
        "\n",
        "class RNVPBlock(nn.Module):\n",
        "    mask: torch.Tensor\n",
        "    comask: torch.Tensor\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        kernel_size: int,\n",
        "        num_channels: int,\n",
        "        s_nets: List[nn.Module],\n",
        "        t_nets: List[nn.Module],\n",
        "        *,\n",
        "        apply_tanh: bool = True,\n",
        "        use_ckpt: bool  = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert len(s_nets) == len(t_nets), \"Need the same number of s and t networks\"\n",
        "        self.s_nets  = nn.ModuleList(s_nets)\n",
        "        self.t_nets  = nn.ModuleList(t_nets)\n",
        "        self.apply_tanh = apply_tanh\n",
        "        self.use_ckpt   = use_ckpt\n",
        "\n",
        "        mask, comask = create_masks(kernel_size, num_channels)\n",
        "        self.register_buffer(\"mask\",   mask)        # (C,H,W)\n",
        "        self.register_buffer(\"comask\", comask)\n",
        "\n",
        "\n",
        "    def _checkpoint(self, fn, x):\n",
        "        if self.training and self.use_ckpt and x.requires_grad:\n",
        "            return checkpoint(fn, x, use_reentrant=False)   # saves memory\n",
        "        else:\n",
        "            return fn(x)\n",
        "\n",
        "    def _one_forward_flow(\n",
        "        self, x: torch.Tensor, s_net: nn.Module, t_net: nn.Module\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "        x1, x2 = x * self.mask, x * self.comask\n",
        "\n",
        "        # step 1: mask -> comask\n",
        "        s1 = self.comask * self._checkpoint(s_net, x1)\n",
        "        t1 = self.comask * self._checkpoint(t_net, x1)\n",
        "        if self.apply_tanh:  s1 = torch.tanh(s1)\n",
        "        x2_ = self.comask * (torch.exp(s1) * x2 + t1)\n",
        "        ldj  = s1.sum(dim=(1, 2, 3))\n",
        "\n",
        "        # step 2: comask -> mask\n",
        "        s2 = self.mask * self._checkpoint(s_net, x2_)\n",
        "        t2 = self.mask * self._checkpoint(t_net, x2_)\n",
        "        if self.apply_tanh:  s2 = torch.tanh(s2)\n",
        "        x1_ = self.mask * (torch.exp(s2) * x1 + t2)\n",
        "        ldj += s2.sum(dim=(1, 2, 3))\n",
        "\n",
        "        return x1_ + x2_, ldj\n",
        "\n",
        "    def _one_inverse_flow(\n",
        "        self, x: torch.Tensor, s_net: nn.Module, t_net: nn.Module\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "        x1, x2 = x * self.mask, x * self.comask\n",
        "\n",
        "        # step 2⁻¹\n",
        "        s2 = self.mask * self._checkpoint(s_net, x2)\n",
        "        t2 = self.mask * self._checkpoint(t_net, x2)\n",
        "        if self.apply_tanh:  s2 = torch.tanh(s2)\n",
        "        x1_ = self.mask * torch.exp(-s2) * (x1 - t2)\n",
        "        ldj  = -s2.sum(dim=(1, 2, 3))\n",
        "\n",
        "        # step 1⁻¹\n",
        "        s1 = self.comask * self._checkpoint(s_net, x1_)\n",
        "        t1 = self.comask * self._checkpoint(t_net, x1_)\n",
        "        if self.apply_tanh:  s1 = torch.tanh(s1)\n",
        "        x2_ = self.comask * torch.exp(-s1) * (x2 - t1)\n",
        "        ldj -= s1.sum(dim=(1, 2, 3))\n",
        "\n",
        "        return x1_ + x2_, ldj\n",
        "\n",
        "    def forward(self, x):\n",
        "        ldj = torch.zeros(x.size(0), device=x.device)\n",
        "        for s_net, t_net in zip(self.s_nets, self.t_nets):\n",
        "            x, inc = self._one_forward_flow(x, s_net, t_net)\n",
        "            ldj += inc\n",
        "        return x, ldj\n",
        "\n",
        "    def inverse(self, z):\n",
        "        ldj = torch.zeros(z.size(0), device=z.device)\n",
        "        for s_net, t_net in zip(reversed(self.s_nets), reversed(self.t_nets)):\n",
        "            z, inc = self._one_inverse_flow(z, s_net, t_net)\n",
        "            ldj += inc\n",
        "        return z, ldj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z67hAmd_Ym7i"
      },
      "outputs": [],
      "source": [
        "def shift_kernel_blocks(x: torch.Tensor, m: int, h:int, inverse : bool = False) -> torch.Tensor:\n",
        "    shift = (m // 2) * (2 ** h)\n",
        "    if not inverse:\n",
        "        return torch.roll(x, shifts=(-shift, -shift), dims=(-2, -1))\n",
        "    else:\n",
        "        return torch.roll(x, shifts=(shift, shift), dims=(-2, -1))\n",
        "\n",
        "class MERABlock(nn.Module):\n",
        "    def __init__(self, m, h, network, shift=False):\n",
        "        super().__init__()\n",
        "        self.m = m\n",
        "        self.h = h\n",
        "        self.network = network # Should have forward and inverse methods\n",
        "        self.dilation = 2 ** h\n",
        "        self.stride = m * self.dilation\n",
        "        self.unfold = nn.Unfold(kernel_size=m, dilation=self.dilation, stride=self.stride)\n",
        "        self.fold = None\n",
        "        self.shift = shift\n",
        "        self.cached_mask = None\n",
        "\n",
        "    def _apply_flow(self, x, flow_method):\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        x_orig = x\n",
        "        x_to_process = x\n",
        "        if self.shift:\n",
        "            x_to_process = shift_kernel_blocks(x, self.m, self.h)\n",
        "\n",
        "        patches = self.unfold(x_to_process)\n",
        "\n",
        "        num_patches = patches.shape[-1]\n",
        "        patches_reshaped = patches.view(B, C, self.m, self.m, num_patches).permute(0, 4, 1, 2, 3).reshape(B * num_patches, C, self.m, self.m)\n",
        "\n",
        "        # Apply the specified flow method (forward or inverse)\n",
        "        transformed_patches, ldj = flow_method(patches_reshaped)\n",
        "\n",
        "        transformed_patches_reshaped = transformed_patches.view(B, num_patches, C, self.m, self.m).permute(0, 2, 3, 4, 1).reshape(B, C * self.m * self.m, num_patches)\n",
        "\n",
        "        if self.fold is None:\n",
        "            self.fold = nn.Fold(output_size=(H, W), kernel_size=self.m, dilation=self.dilation, stride=self.stride)\n",
        "            with torch.no_grad():\n",
        "                single_item_patches = patches.narrow(0, 0, 1)\n",
        "                self.cached_mask = self.fold(torch.ones_like(single_item_patches))\n",
        "\n",
        "        folded = self.fold(transformed_patches_reshaped)\n",
        "\n",
        "        mask = self.cached_mask.expand(B, C, H, W)\n",
        "\n",
        "        if self.shift:\n",
        "            folded = shift_kernel_blocks(folded, self.m, self.h, inverse=True)\n",
        "            mask = shift_kernel_blocks(mask, self.m, self.h, inverse=True)\n",
        "\n",
        "        x_updated = torch.where(mask.bool(), folded, x_orig)\n",
        "\n",
        "        return x_updated, ldj.view(B, -1).sum(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._apply_flow(x, self.network.forward)\n",
        "\n",
        "    def inverse(self, x):\n",
        "        return self._apply_flow(x, self.network.inverse)\n",
        "\n",
        "class RG_Flow(nn.Module):\n",
        "    \"\"\"A full MERA model built from a sequence of MERABlock layers.\"\"\"\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ldj = torch.zeros(x.shape[0], device=x.device)\n",
        "        for layer in self.layers:\n",
        "            x, ldj_ = layer.forward(x)\n",
        "            ldj += ldj_\n",
        "        return x, ldj\n",
        "\n",
        "    def inverse(self, x):\n",
        "        ldj = torch.zeros(x.shape[0], device=x.device)\n",
        "        for layer in reversed(self.layers):\n",
        "            x, ldj_ = layer.inverse(x)\n",
        "            ldj += ldj_\n",
        "        return x, ldj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RW8iBRC5YrWP"
      },
      "outputs": [],
      "source": [
        "class PriorDistribution(nn.Module):\n",
        "    def __init__(self, dist_type='laplace'):\n",
        "        super().__init__()\n",
        "        if dist_type == 'laplace':\n",
        "            self.base_dist = D.Laplace\n",
        "        elif dist_type == 'gaussian':\n",
        "            self.base_dist = D.Normal\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported distribution type: {dist_type}\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"PriorDistribution(dist_type={self.base_dist.__name__})\"\n",
        "\n",
        "    def log_prob(self, z, temperature=1.0):\n",
        "        dist = self.base_dist(loc=torch.zeros_like(z), scale=torch.ones_like(z) * temperature)\n",
        "        return dist.log_prob(z).sum(dim=[1, 2, 3]) # Sum over all dimensions except batch\n",
        "\n",
        "    def sample(self, shape, temperature=1.0):\n",
        "        dist = self.base_dist(loc=torch.zeros(shape), scale=torch.ones(shape) * temperature)\n",
        "        return dist.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRpZupytYuPb"
      },
      "outputs": [],
      "source": [
        "n_layers = [4, 4, 4, 4, 4, 4, 4, 4]\n",
        "\n",
        "layers = []\n",
        "for n in n_layers:\n",
        "    s_nets = [ResidualNetwork() for _ in range(n)]\n",
        "    t_nets = [ResidualNetwork() for _ in range(n)]\n",
        "    layers.append(RNVPBlock(kernel_size=4, num_channels=3, s_nets=s_nets, t_nets=t_nets, apply_tanh=True, use_ckpt=True))\n",
        "\n",
        "MERA_layers = []\n",
        "for i, layer in enumerate(layers):\n",
        "    MERA_layers.append(\n",
        "        MERABlock(m=4, h = i // 2, network=layer, shift=(i % 2 == 1))\n",
        "    )\n",
        "flow = RG_Flow(MERA_layers)\n",
        "flow.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdPdrZCPZJyQ"
      },
      "outputs": [],
      "source": [
        "def logit_transform(x, dequant=True, constraint=0.9, inverse=False):\n",
        "    if inverse:\n",
        "        logit_x = x\n",
        "        pre_logit_scale = torch.tensor(log(constraint) - log(1 - constraint))\n",
        "        ldj = (F.softplus(logit_x) + F.softplus(-logit_x) -\n",
        "               F.softplus(-pre_logit_scale))\n",
        "        ldj = ldj.view(ldj.shape[0], -1).sum(dim=1)\n",
        "        x = 1 / (1 + torch.exp(-logit_x))\n",
        "        x *= 2\n",
        "        x -= 1\n",
        "        x /= constraint\n",
        "        x += 1\n",
        "        x /= 2\n",
        "\n",
        "        return x, ldj\n",
        "\n",
        "    else:\n",
        "        if dequant:\n",
        "            noise = torch.rand_like(x)\n",
        "            x = (x * 255 + noise) / 256\n",
        "\n",
        "        x *= 2\n",
        "        x -= 1\n",
        "        x *= constraint\n",
        "        x += 1\n",
        "        x /= 2\n",
        "\n",
        "        logit_x = torch.log(x) - torch.log(1 - x)\n",
        "\n",
        "        pre_logit_scale = torch.tensor(log(constraint) - log(1 - constraint))\n",
        "        ldj = (F.softplus(logit_x) + F.softplus(-logit_x) -\n",
        "               F.softplus(-pre_logit_scale))\n",
        "        ldj = ldj.view(ldj.shape[0], -1).sum(dim=1)\n",
        "\n",
        "        return logit_x, ldj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhJWEsTzZKsU"
      },
      "outputs": [],
      "source": [
        "def generate_and_show_images(\n",
        "    model: RG_Flow,\n",
        "    prior: PriorDistribution,\n",
        "    epoch: int,\n",
        "    num_images: int,\n",
        "    image_dims: tuple,\n",
        "    device: str,\n",
        "    save_dir: str = \"generated_images\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates images from the model, displays them, and saves them to a file.\n",
        "\n",
        "    Args:\n",
        "        model: The RG_Flow model instance.\n",
        "        prior: The prior distribution.\n",
        "        epoch: The current epoch number (for titling and saving).\n",
        "        num_images: The number of images to generate.\n",
        "        image_dims: A tuple of (channels, height, width).\n",
        "        device: The device to run generation on.\n",
        "        save_dir: Directory to save the generated images.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        n_channels, height, width = image_dims\n",
        "        z_shape = (num_images, n_channels, height, width)\n",
        "        z = prior.sample(z_shape).to(device)\n",
        "\n",
        "\n",
        "        generated_logits, _ = model.inverse(z)\n",
        "\n",
        "\n",
        "        generated_images, _ = logit_transform(generated_logits, dequant=False, inverse=True)\n",
        "\n",
        "\n",
        "        generated_images = generated_images.cpu()\n",
        "\n",
        "\n",
        "        generated_images = torch.clamp(generated_images, 0, 1)\n",
        "\n",
        "\n",
        "    grid = torchvision.utils.make_grid(generated_images, nrow=int(sqrt(num_images)))\n",
        "    img_grid = grid.permute(1, 2, 0).numpy()\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img_grid)\n",
        "    plt.title(f\"Generated Images at Epoch {epoch + 1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.savefig(os.path.join(save_dir, f\"epoch_{epoch+1:03d}.png\"))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyL3CvbVZNXr"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_logger(name='rg_flow_training'):\n",
        "    \"\"\"\n",
        "    Sets up a logger that writes to a file and the console.\n",
        "    \"\"\"\n",
        "    # Create a logger\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO) # Set the minimum level of messages to log\n",
        "\n",
        "    # Prevent the logger from propagating to the root logger\n",
        "    logger.propagate = False\n",
        "\n",
        "    # Create a formatter\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s',\n",
        "                                  datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # --- File Handler ---\n",
        "    # Create a unique log file name with a timestamp\n",
        "    log_filename = f\"training_run_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log\"\n",
        "    file_handler = logging.FileHandler(log_filename)\n",
        "    file_handler.setFormatter(formatter)\n",
        "\n",
        "    # --- Console Handler ---\n",
        "    stream_handler = logging.StreamHandler() # Writes to console\n",
        "    stream_handler.setFormatter(formatter)\n",
        "\n",
        "    # Add handlers to the logger, but only if they haven't been added before\n",
        "    if not logger.handlers:\n",
        "        logger.addHandler(file_handler)\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPu-CEyYZP72"
      },
      "outputs": [],
      "source": [
        "def train_rg_flow(\n",
        "    model: RG_Flow,\n",
        "    prior: PriorDistribution,\n",
        "    train_loader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    num_epochs: int,\n",
        "    device: str,\n",
        "    image_dims: tuple,\n",
        "    logger: logging.Logger,\n",
        "    num_images_to_generate: int = 16\n",
        "):\n",
        "    \"\"\"\n",
        "    The main training loop for the RG-Flow model.\n",
        "    ... (args documentation) ...\n",
        "    Args:\n",
        "        logger: A configured logger object.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    prior.to(device)\n",
        "\n",
        "    n_channels, height, width = image_dims\n",
        "    bpd_factor = np.log(2) * n_channels * height * width\n",
        "    logger.info(f\"Training for {num_epochs} epochs...\")\n",
        "    logger.info(f\"Batch size: {BATCH_SIZE}\")\n",
        "    logger.info(f\"Learning rate: {LEARNING_RATE}\")\n",
        "    logger.info(f\"Image dimensions: {image_dims}\")\n",
        "    logger.info(f\"Number of images to generate: {num_images_to_generate}\")\n",
        "    logger.info(prior)\n",
        "\n",
        "    logger.info(\"--- Starting Training ---\")\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_idx, (x, _) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            x = x.to(device)\n",
        "            x, ldj_logit = logit_transform(x)\n",
        "            z_final, ldj_combined = model.forward(x)\n",
        "            logp_prior = prior.log_prob(z_final)\n",
        "            total_log_likelihood = logp_prior + ldj_combined + ldj_logit\n",
        "            loss = -torch.mean(total_log_likelihood)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 50 == 0: # Log less frequently for a cleaner file\n",
        "                bpd = (loss.item() + np.log(256.) * (n_channels * height * width)) / bpd_factor\n",
        "                logger.info(f\"Epoch: {epoch+1}/{num_epochs} | Batch: {batch_idx}/{len(train_loader)} | Loss (NLL): {loss.item():.4f} | BPD: {bpd:.4f}\")\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        logger.info(f\"--- Epoch {epoch+1} Summary ---\")\n",
        "        logger.info(f\"Average Loss: {avg_loss:.4f} | Time: {epoch_time:.2f}s\")\n",
        "\n",
        "        logger.info(\"Generating sample images...\")\n",
        "        generate_and_show_images(\n",
        "            model=model,\n",
        "            prior=prior,\n",
        "            epoch=epoch,\n",
        "            num_images=num_images_to_generate,\n",
        "            image_dims=image_dims,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        logger.info(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lsHA9_jZS_c"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 32\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE = batch_size\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS = 60\n",
        "prior_str = \"laplace\"\n",
        "prior = PriorDistribution(dist_type=prior_str)\n",
        "\n",
        "\n",
        "logger = setup_logger()\n",
        "optimizer = torch.optim.AdamW(flow.parameters(), lr=LEARNING_RATE, weight_decay=5e-5)\n",
        "\n",
        "\n",
        "try:\n",
        "    train_rg_flow(\n",
        "        model=flow,\n",
        "        prior=prior,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        device=DEVICE,\n",
        "        image_dims=(NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE),\n",
        "        logger=logger,\n",
        "        num_images_to_generate=16\n",
        "    )\n",
        "except Exception as e:\n",
        "    logger.error(\"An error occurred during training!\", exc_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa8lLrmDZfcT"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "# Download the generated images directory\n",
        "!zip -r generated_images.zip generated_images\n",
        "files.download('generated_images.zip')\n",
        "# Download the model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-qajeAtZY5D"
      },
      "outputs": [],
      "source": [
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a timestamp for the filename\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "MODEL_WEIGHTS_PATH = f\"rg_flow_weights_{timestamp}_{NUM_EPOCHS}_MSD2_{prior_str}.pth\"\n",
        "\n",
        "print(f\"Saving model weights to {MODEL_WEIGHTS_PATH}...\")\n",
        "\n",
        "# Use model.state_dict() to get the dictionary of weights\n",
        "torch.save(flow.state_dict(), MODEL_WEIGHTS_PATH)\n",
        "\n",
        "print(\"Model weights saved successfully.\")\n",
        "files.download(MODEL_WEIGHTS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5GtwDLrZi7i"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the path for saving the optimizer state\n",
        "optimizer_path = f\"rg_flow_optimizer_{timestamp}_{NUM_EPOCHS}_MSD2_{prior_str}.pth\"\n",
        "\n",
        "print(f\"Saving optimizer state to {optimizer_path}...\")\n",
        "\n",
        "# Save the state_dict of the optimizer\n",
        "torch.save(optimizer.state_dict(), optimizer_path)\n",
        "\n",
        "print(\"Optimizer state saved successfully.\")\n",
        "\n",
        "# Download the optimizer state file\n",
        "files.download(optimizer_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}